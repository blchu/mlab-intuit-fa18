{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import en_coref_md\n",
    "import en_coref_sm\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from termcolor import colored\n",
    "cur = '/Users/apple/Desktop/é’»/Projects/mlab-intuit-fa18/CNNDatasetAnalysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullTextTexts = pickle.load(open(cur+'processedData/Texts.pkl','rb'))\n",
    "fullTextSentences = pickle.load(open(cur+'processedData/textSentences.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assume data is taken in as list of list of words (lsls)\n",
    "## Since spacy takes the whole string as resolution input, so first need to merge lsls into one document text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hard coding for some examples of exception \n",
    "period_ls = {'Mr.': 'Mr', 'Mrs.': 'Mrs', 'Dr.': 'Dr', 'Gov.':'Gov'}\n",
    "\n",
    "def isPunctuation(word):\n",
    "    return False if re.match(\"^[a-zA-Z0-9_\\-]*$\", word) else True\n",
    "\n",
    "# merge documents from a list of list of list of words to one document str\n",
    "def mergeDoc(lslsls):\n",
    "    docs = []\n",
    "    for doc in lslsls:\n",
    "        doc_str = \"\"\n",
    "        for sen in doc:    \n",
    "            for word in sen:  \n",
    "                ## prevent leading spaces\n",
    "                if isPunctuation(word) or doc_str == \"\": \n",
    "                    doc_str += word\n",
    "                ## remove new line\n",
    "                elif word != '\\n':   \n",
    "                    doc_str += \" \" + word                \n",
    "        docs.append(doc_str)\n",
    "    return docs\n",
    "\n",
    "# preprocess the document string (removing unusual periods: U.S.A, Dr.Who)\n",
    "def preprocess(doc_str):\n",
    "\n",
    "    ## Remove . in acronyms \n",
    "    ## NOTE: not distinguishing if the acronym ends the sentence (where period should be kept)\n",
    "    doc = re.sub(r'(?<!\\w)([A-Z])\\.', r'\\1', doc_str)\n",
    "    ## TODO: use Regex not for-loop\n",
    "    for k, v in period_ls.items():\n",
    "        doc = doc.replace(k, v)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullText = [preprocess(x) for x in mergeDoc(fullTextSentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullText = pickle.load( open( \"fullText.p\", \"rb\" ) )\n",
    "#pickle.dump(fullText, open(\"fullText.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying spacy's coreference resolution to obtain coreference clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to help locate coreference clusters and their mentions\n",
    "\n",
    "Since spacy gives the arbitrary position of each mention (sometimes that does not align with the word positions we have depending on how they break their sentences/words/punctuations), building a dictionary that stores both sentence start and ending positions to help search flexibly in a range.\n",
    "\n",
    "Note: funtions applies to a single document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input: list of list of words\n",
    "## return: a dictionary (key: sentence positions; value: [start word pos, end word pos])\n",
    "def labelPositions(lsls):\n",
    "    sen_pos = 0\n",
    "    word_pos = 0\n",
    "    label_dic = {}\n",
    "    for sen in lsls:\n",
    "        start = word_pos\n",
    "        end = word_pos + len(sen) - 1\n",
    "        label_dic[sen_pos] = [start,end]\n",
    "        word_pos = end + 1\n",
    "        sen_pos += 1\n",
    "    return label_dic\n",
    "\n",
    "## Input: word position\n",
    "## Return: the sentence position in which the word is located\n",
    "def findSen(dic, word_pos):\n",
    "    for k,v in dic.items():\n",
    "        if(word_pos >= v[0] and word_pos <= v[1]):\n",
    "            return k\n",
    "    raise IndexError(\"word position is out of bound\")\n",
    "    return\n",
    "\n",
    "\n",
    "## Find the sublist of ls that is an exact match to the pattern\n",
    "## return the first set of index of sublist\n",
    "def subfinderFirst(ls, pattern):\n",
    "    match_index = []\n",
    "    for wi in (range(len(ls))):\n",
    "        for pi in (range(len(pattern))):\n",
    "            if wi+pi >= len(ls) or ls[wi+pi].lower() != pattern[pi].lower():\n",
    "                break\n",
    "            if pi == len(pattern) - 1:\n",
    "                match_index += list(range(wi,wi+len(pattern)))\n",
    "                return match_index\n",
    "\n",
    "## (Currently not used)            \n",
    "## return all indices for elements of sublist\n",
    "def subfinder(ls, pattern):\n",
    "    match_index = []\n",
    "    for wi in (range(len(ls))):\n",
    "        for pi in (range(len(pattern))):\n",
    "            if wi+pi >= len(ls) or ls[wi+pi].lower() != pattern[pi].lower():\n",
    "                break\n",
    "            if pi == len(pattern) - 1:\n",
    "                match_index += list(range(wi,wi+len(pattern)))\n",
    "    return match_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolution\n",
    "Rules:\n",
    "1. If the identity is in the same sentence, do not resolve;\n",
    "2. Similarly, do not resolve more than once for the same identity in the same sentence;\n",
    "3. When there are multiple choices (after passing rule 1 and 2), resolve the first reference. \n",
    "(**Issue: may replace the instance from another cluster in the same sentence**) \n",
    "4. Only replace references that come after the identity\n",
    "\n",
    "Corner cases:\n",
    "1. Replace possessive pronouns with identity + 's\n",
    "2. Replace 're with identity + 'are'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSESSIVE_PRONOUNS = ['their', 'its', 'his', 'her', 'hers', 'theirs', 'my', 'mine', 'your', 'yours']\n",
    "FUZZY_SEN = 6\n",
    "\n",
    "# doc: a single document in a str (from FullText)\n",
    "# dic: labeled word pos dictionary for a single doc\n",
    "# mod: spacy model for a single doc\n",
    "# lsls: list of list of words (from FullTextSentences)\n",
    "def resolution(mod, dic, doc, lsls):\n",
    "    \n",
    "    for cluster in mod._.coref_clusters:\n",
    "        identity = str(cluster.main)\n",
    "        identity_sen = findSen(dic, cluster.main.start)  ## TODO: or use mention[0]\n",
    "        replaced_sen = []\n",
    "        for ref in cluster.mentions:\n",
    "            if str(ref).lower() != str(cluster.main).lower(): ## e.g. Cluster like [\"He\", \"he\"] is ignored\n",
    "                sen_index = findSen(dic,ref.start)\n",
    "                \n",
    "                ## Note: only replace references that come after the identity\n",
    "                if sen_index > identity_sen and sen_index not in replaced_sen: \n",
    "                    possible_indices = []\n",
    "                    possible_sen = []\n",
    "                    for i in range(-1,FUZZY_SEN):\n",
    "                        if identity_sen < sen_index+i < len(lsls):\n",
    "                            possible_indices.append(sen_index+i)\n",
    "                            possible_sen.append(lsls[sen_index+i])\n",
    "                    \n",
    "                    \n",
    "                    ref_sen, id = selectReplace(possible_sen, identity, str(ref), dic)\n",
    "                    if id is not None and ref_sen is not None:\n",
    "                        ref_sen_index = possible_indices[id]\n",
    "                        replaced_sen.append(ref_sen_index)\n",
    "                    \n",
    "                        ## mutate actual sentence\n",
    "                        lsls[ref_sen_index] = ref_sen\n",
    "    return\n",
    "\n",
    "# sentences: a list of candidate sentence that may contain the reference\n",
    "# identity: word str\n",
    "# ref: word str\n",
    "# dic: to update dictionary after each resolve\n",
    "# return: resolved sentence as a word list, sentence index (in the list), change of word count to update dic\n",
    "def selectReplace(sentences, identity, ref, dic): ## FOR DEBUGGING\n",
    "    replace_str = identity\n",
    "    \n",
    "    ##1. Deal with corner cases:\n",
    "    # sync capitalization between ref and identity\n",
    "    if ref[0].isupper() and replace_str[0].islower():\n",
    "        replace_str = replace_str[0].upper() + replace_str[1:]\n",
    "        print(replace_str)\n",
    "    \n",
    "    if ref[0].islower() and replace_str[0].isupper():\n",
    "        replace_str = replace_str[0].lower() + replace_str[1:]\n",
    "        print(replace_str)\n",
    "        \n",
    "    # replacing possessive pronouns\n",
    "    if ref.lower() in POSSESSIVE_PRONOUNS:\n",
    "        if replace_str[-2:] != \"'s\": ## if 's is not already in str\n",
    "            replace_str = replace_str+\"'s\" \n",
    "    \n",
    "    ##2. Locate reference to be replaced within a fuzzy range:\n",
    "    identity_ls = replace_str.split(\" \")\n",
    "    ref_ls = ref.split(\" \")\n",
    "    replace_index = subfinderFirst(sentences[0], ref_ls)\n",
    "    sentence = sentences[0]\n",
    "    sentence_id = 0\n",
    "        \n",
    "    for i in range(FUZZY_SEN): ##TODO: while-loop\n",
    "        if replace_index is not None:\n",
    "            sentence_id = i\n",
    "            break\n",
    "        if replace_index is None:\n",
    "            replace_index = subfinderFirst(sentences[i], ref_ls)\n",
    "            sentence = sentences[i]\n",
    "\n",
    "    ## DEBUGGING\n",
    "    if replace_index is None:\n",
    "        if DEBUG:\n",
    "            #print(\"ref.start: \", start)\n",
    "            #s = findSen(dic, start)\n",
    "            print(\"ref word: \", ref)\n",
    "            print(\"in range: \", dic[s])\n",
    "            for i in range(5):\n",
    "                print(\"earlier: \", fullTextSentences[TEST_INDEX][s-i])\n",
    "                print(\"later: \", fullTextSentences[TEST_INDEX][s+i])\n",
    "        return\n",
    "    \n",
    "    if PRINT:\n",
    "        print(\"###\\nBefore: \") \n",
    "        mark_sen(sentence, replace_index)\n",
    "\n",
    "    ## messy corner cases:\n",
    "    ## \"they're\" --> \"[identity] are\"\n",
    "    if sentence[replace_index[-1]+1] == '\\'re':\n",
    "        sentence[replace_index[-1]+1] = 'are'\n",
    "    \n",
    "    ##3. Resolve\n",
    "    for j in replace_index:\n",
    "        if j > len(sentence):\n",
    "            print(\"j \", j)\n",
    "            print(\"len\", len(sentence))\n",
    "        del sentence[j]\n",
    "    identity_ls.reverse()\n",
    "    for word in identity_ls:\n",
    "        sentence.insert(replace_index[0], word)\n",
    "    replace_pos = range(replace_index[0], replace_index[0]+len(identity_ls))   \n",
    "    \n",
    "    if PRINT:\n",
    "        print(\"After: \")   \n",
    "        mark_sen(sentence, replace_pos)\n",
    "    \n",
    "    \n",
    "    return \" \".join(sentence), sentence_id\n",
    "\n",
    "def mark_sen(sen, highlight_index):\n",
    "    for word, index in zip(sen,range(len(sen))):\n",
    "        if(index in highlight_index):\n",
    "            print(\" \", colored(word, 'red'), end = \"\")\n",
    "        elif(isPunctuation(word)):\n",
    "            print(word, end= \"\")\n",
    "        else:  \n",
    "            print(\" \", word, end= \"\")\n",
    "    print(\"\\n\")\n",
    "    return\n",
    "\n",
    "## (currently not used)\n",
    "def update_dic(dic, sen_pos, end_change):\n",
    "    start = dic[sen_pos][0]\n",
    "    end = dic[sen_pos][1]\n",
    "    new_pos = [start, end+end_change]\n",
    "    dic[sen_pos] = new_pos\n",
    "    for k, v in dic.items():\n",
    "        if k > sen_pos:\n",
    "            v[0] += end_change\n",
    "            v[1] += end_change\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "louisiana Gov Bobby Jindal\n",
      "###\n",
      "Before: \n",
      "  Bobby  Jindal  on  Monday  stood  by  \u001b[31mhis\u001b[0m  criticism  of  so-called``  no-go''  zones  in  Europe,  where  sovereign  nations  allegedly  cede  authority  to  Muslim  immigrants,  a  controversial  idea  that  many  critics  say  is  overblown.\n",
      "\n",
      "After: \n",
      "  Bobby  Jindal  on  Monday  stood  by  \u001b[31mlouisiana\u001b[0m  \u001b[31mGov\u001b[0m  \u001b[31mBobby\u001b[0m  \u001b[31mJindal's\u001b[0m  criticism  of  so-called``  no-go''  zones  in  Europe,  where  sovereign  nations  allegedly  cede  authority  to  Muslim  immigrants,  a  controversial  idea  that  many  critics  say  is  overblown.\n",
      "\n",
      "louisiana Gov Bobby Jindal\n",
      "###\n",
      "Before: \n",
      "  And  the  potential  2016  Republican  presidential  candidate  decried  what  \u001b[31mhe\u001b[0m  called  immigrants'  insistence  on``  non-assimilation,  the  fact  that``  you've  got  people  who  want  to  come  to  our  country  but  not  adopt  our  values,''  which  he  called``  dangerous.\n",
      "\n",
      "After: \n",
      "  And  the  potential  2016  Republican  presidential  candidate  decried  what  \u001b[31mlouisiana\u001b[0m  \u001b[31mGov\u001b[0m  \u001b[31mBobby\u001b[0m  \u001b[31mJindal\u001b[0m  called  immigrants'  insistence  on``  non-assimilation,  the  fact  that``  you've  got  people  who  want  to  come  to  our  country  but  not  adopt  our  values,''  which  he  called``  dangerous.\n",
      "\n",
      "louisiana Gov Bobby Jindal\n",
      "###\n",
      "Before: \n",
      "  And  the  potential  2016  Republican  presidential  candidate  decried  what  louisiana  Gov  Bobby  Jindal  called  immigrants'  insistence  on``  non-assimilation,  the  fact  that``  you've  got  people  who  want  to  come  to  our  country  but  not  adopt  our  values,''  which  \u001b[31mhe\u001b[0m  called``  dangerous.\n",
      "\n",
      "After: \n",
      "  And  the  potential  2016  Republican  presidential  candidate  decried  what  louisiana  Gov  Bobby  Jindal  called  immigrants'  insistence  on``  non-assimilation,  the  fact  that``  you've  got  people  who  want  to  come  to  our  country  but  not  adopt  our  values,''  which  \u001b[31mlouisiana\u001b[0m  \u001b[31mGov\u001b[0m  \u001b[31mBobby\u001b[0m  \u001b[31mJindal\u001b[0m  called``  dangerous.\n",
      "\n",
      "jindal\n",
      "###\n",
      "Before: \n",
      "  And  I'm  also  making  a  bigger  and  maybe  even  more  controversial  point  that  radical  Islam  is  a  grave  threat,  we  need  Muslim  leaders  to  denounce  the  individuals,  not  just  the  acts  of  violence,''  \u001b[31mhe\u001b[0m  said,  adding  that``  it  is  absolutely  correct  to  insist  on  assimilation''  of  immigrants  in  the  United  States.\n",
      "\n",
      "After: \n",
      "  And  I'm  also  making  a  bigger  and  maybe  even  more  controversial  point  that  radical  Islam  is  a  grave  threat,  we  need  Muslim  leaders  to  denounce  the  individuals,  not  just  the  acts  of  violence,''  \u001b[31mjindal\u001b[0m  said,  adding  that``  it  is  absolutely  correct  to  insist  on  assimilation''  of  immigrants  in  the  United  States.\n",
      "\n",
      "jindal\n",
      "###\n",
      "Before: \n",
      "  Jindal  was  also  unable  to  offer  examples  during  an  earlier  interview  with  CNN's  Max  Foster,  saying  that  \u001b[31mhe\u001b[0m's``  heard  from  folks  here  that  there  are  neighborhoods  where  women  don't  feel  comfortable  going  in  without  veils.\n",
      "\n",
      "After: \n",
      "  Jindal  was  also  unable  to  offer  examples  during  an  earlier  interview  with  CNN's  Max  Foster,  saying  that  \u001b[31mjindal\u001b[0m's``  heard  from  folks  here  that  there  are  neighborhoods  where  women  don't  feel  comfortable  going  in  without  veils.\n",
      "\n",
      "jindal\n",
      "###\n",
      "Before: \n",
      "  Pretending  it's  not  here  won't  make  it  go  away,''  \u001b[31mhe\u001b[0m  told  Foster.\n",
      "\n",
      "After: \n",
      "  Pretending  it's  not  here  won't  make  it  go  away,''  \u001b[31mjindal\u001b[0m  told  Foster.\n",
      "\n",
      "###\n",
      "Before: \n",
      "  Pretending  \u001b[31mit\u001b[0m's  not  here  won't  make  it  go  away,''  jindal  told  Foster.\n",
      "\n",
      "After: \n",
      "  Pretending  \u001b[31mthis\u001b[0m  \u001b[31mproblem\u001b[0m's  not  here  won't  make  it  go  away,''  jindal  told  Foster.\n",
      "\n",
      "jindal\n",
      "###\n",
      "Before: \n",
      "  I  believe  it  is  because  radical  Islamists  have  been  given  too  wide  a  berth  to  establish  their  own  nation  within  a  nation,''  \u001b[31mhe\u001b[0m  said.\n",
      "\n",
      "After: \n",
      "  I  believe  it  is  because  radical  Islamists  have  been  given  too  wide  a  berth  to  establish  their  own  nation  within  a  nation,''  \u001b[31mjindal\u001b[0m  said.\n",
      "\n",
      "jindal\n",
      "###\n",
      "Before: \n",
      "  Muslim  leaders  need  to``  condemn  anyone  who  commits  these  acts  of  violence,  and  clearly  state  that  these  people  are  evil  and  are  enemies  of  Islam,''  \u001b[31mhe\u001b[0m  added.\n",
      "\n",
      "After: \n",
      "  Muslim  leaders  need  to``  condemn  anyone  who  commits  these  acts  of  violence,  and  clearly  state  that  these  people  are  evil  and  are  enemies  of  Islam,''  \u001b[31mjindal\u001b[0m  added.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-1fb5e8ae6c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfullTextSentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'processedData/textSentences.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## replacement mutates the str list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST_INDEX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## using fullText here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST_INDEX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullTextSentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST_INDEX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-161-b4475122afa4>\u001b[0m in \u001b[0;36mresolution\u001b[0;34m(mod, dic, doc, lsls)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mref_sen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectReplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_sen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mref_sen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0mref_sen_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpossible_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "DEBUG = 0\n",
    "PRINT = 1\n",
    "TEST_INDEX = 4\n",
    "dic  = labelPositions(fullTextSentences[TEST_INDEX]) ## using fullTextSentences here\n",
    "fullTextSentences = pickle.load(open(cur+'processedData/textSentences.pkl','rb')) ## replacement mutates the str list\n",
    "mod = nlp(fullText[TEST_INDEX]) ## using fullText here\n",
    "resolution(mod, dic, fullText[TEST_INDEX], fullTextSentences[TEST_INDEX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_coref_md.load()\n",
    "def resolve_all(lslsls):\n",
    "    for lsls in lslsls:\n",
    "        dic  = labelPositions(lsls) \n",
    "        full = [preprocess(mergeDoc(lsls)[0])]\n",
    "        mod = nlp(full)\n",
    "        resolution(mod, dic, full, lsls) ## TODO: Does this mutate in place\n",
    "    return lslsls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
